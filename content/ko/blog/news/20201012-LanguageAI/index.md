---
date: 2020-10-12
title: "SK텔레콤은 '언어신동 AI’에 어떻게 한국어를 가르쳤을까"
linkTitle: "SK텔레콤은 '언어신동 AI’에 어떻게 한국어를 가르쳤을까"
description: "영어만 익힌 원형 AI에 한국어 문장 수천만개 가르쳐<br>
한국어 문장 이해·생성 뛰어난 KoBERT·KoGPT2 개발<br>
아마존 클라우드자원·AI기술전문가 도움으로 최적화<br>
다른 활용도 높은 AI '한국어 버전'도 후속 출시 예고"
author: 임민철 기자
resources:
- src: "**.{png,jpg,jpeg}"
  title: "Image #:counter"
  params:
    byline: "아주경제"
---

SK텔레콤 'AI랭귀지테크랩스(ALT Labs)' 연구원들은 한국어를 잘 다루는 AI '코버트(KoBERT)'와 'KoGPT2'를 잇따라 개발했다. 

KoBERT의 원형은 구글이 지난 2018년 10월 공개한 버트(BERT)이며, KoGPT2의 원형은 오픈AI가 지난해 공개한 GPT-2다. BERT는 영어 읽기, GPT-2는 영어 쓰기에 특출난 '언어 신동' AI로 유명세를 얻었다. SK텔레콤은 이들에게 한국어를 열심히 가르친 결과, 내부 업무에 활용해 성과를 얻었고, 지난해 10월 KoBERT를, 올해 2월엔 KoGPT2를 각각 오픈소스로 공개했다.

{{< imgproc kobert Fit "900x600" >}}
KoBERT와 KoGPT2 개발에 참여한 SK텔레콤 AI랭귀지테크랩스(ALT Labs) 연구원들. (왼쪽위부터 시계방향으로) 전희원 리서치엔지니어, 김진 리서치엔지니어, 데이비스 에릭 하트만 소장, 김태윤 리더. [사진=SK텔레콤 제공]
{{< /imgproc >}}

---

자세한 내용은 기사 원문에서 확인하세요. : https://www.ajunews.com/view/20201011091342159
